\section{Related work}


\subsection{Multi-object tracking}

Multi-object tracking is commonly carried out by assigning a single-object tracker to  each target of interest. Current state-of-the-art single-object trackers are based on Deep Learning (DL). A number of approaches rely on Siamese CNNs to discriminate the regions proposed by a region proposal network \cite{zhu2018dasiamrpn, li2019siamrpn++, wang2019siammask, voigtlaender2019trackingsegm}. Other works suggest saving a pool of templates from past track images, the most representative and different among them, and use them to match regions of interest \cite{sauer2019holistic}. Nevertheless, a common drawback of these DL-based methods is that they are computationally expensive and cannot handle long-term tracking: they fail to re-locate out-of-view targets when re-appearing in the scene (see \cite{lin2019mobiface} for a comprehensive survey). A longer-term DL tracker has been very recently proposed in \cite{wangtracking}, but it requires an initial offline training of the model with images from the particular target to track, and thus it is not suitable for our use case.

More computationally efficient trackers are not based on DL, but also achieve competitive accuracies. In \cite{bochinski2018viou}, the use of a Kernelized Correlation Filter (KCF) visual tracker is proposed to fill the gaps generated after applying a classic intersection-over-union (IOU) data association strategy between frame detections. This algorithm works at high frame rates, but still relies heavily on IOU values, which makes it prone to ID-switches. Other high-performing visual trackers include: MOSSE~\cite{bolme2010visual} and CSRT~\cite{lukezic2017discriminative}, which are both based on correlation filters; and the Median Flow tracker \cite{kalal2010forward}, based on motion flow. However, again, these trackers tend to fail with long-term occlusions.


\subsection{Multi-face tracking}

The tracking of persons has been mainly tackled by applying generic object tracking approaches and targeting full-body regions. Few studies rely exclusively on faces to track persons and address face tracking as a problem with its own particularities. 

Taking advantage of the high accuracies reached by current face detectors, many face tracking works propose tracking-by-detection approaches. In \cite{comaschi2015online}, a generic AdaBoost face detector is combined with an adaptive structured output SVM tracker, using a IOU data association strategy. However, this approach is only suitable for short-term tracking, as it does not implement any tracklet reconnection strategy. 
As a longer-term approach, \cite{kalal2010face} applies the Tracking-Learning-Detection (TLD) paradigm to faces: the face is tracked and simultaneously learned by a detector that supports the tracker once it fails. 

More recent approaches achieve long-term face tracking by using clustering techniques to make associations between short-term tracklets \cite{lin2018offline, zhang2016offline}. Short-term tracklets are obtained by combining detectors and simple data association methods. Then, facial features are computed for each detection through DL face recognition models, and clusters are extracted from the feature space to collapse same-identity tracklets. Although these approaches achieve state-of-the-art results, they work fully offline and imply a high computational cost, which is not suitable for real-time tracking.

It is also worth mentioning that some works propose tracking mechanisms to improve face recognition in videos, in scenarios where persons of interest are previously enrolled using few still images. 
In \cite{dewan2016adaptive} and \cite{zheng2018automatic}, simple visual trackers are used to obtain tracks from which new (unseen) high-quality face stills are collected \cite{dewan2016adaptive}. These stills are matched against reference images to identify people. Interestingly, they are additionally used to enrich the gallery of enrolled images, thus improving face recognition performance. 
Nevertheless, these works are devoted to face recognition, and face tracking is just treated as a secondary task. 


\subsection{Datasets for face tracking in crowds}
\label{sec:public_datasets}

Studies on people tracking have traditionally focused on full-body pedestrian tracking in low-to-moderately crowded urban scenes. As a result, several pedestrian video datasets are available and commonly used by the community \cite{li2014datasetCUHK, liu2018datasetShanghaiTech, deng2014datasetPETA}. Another field for which a large number of datasets is available is crowd analysis, e.g. crowd counting or crowd behavior understanding~\cite{rodriguez2011datasetDriven, zhang2015datasetWorldExpo, dendorfer2019cvpr19}. These crowd datasets usually contain high-angle views, in which people faces appear at very low resolutions (mostly below 30x30 pixels). Very recently, the MobiFace dataset has been released to evaluate in-the-wild face tracking algorithms for mobile devices \cite{lin2019mobiface}. Videos are recorded from moving smartphone cameras, sometimes in ``selfie'' mode, and contain few faces (less than 5) per video. Consequently, none of these datasets cover our use case.

The only exception is the ChokePoint dataset. It provides a collection of 48 videos capturing individual subjects walking through two portals \cite{wong2011chokepoint}. To pose a more challenging real-world surveillance problem, two extra sequences were recorded in a indoor crowded environment, which represent the scenarios that we are targeting in this work. 